{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HCIg39APoFk"
   },
   "source": [
    "# Phase 3: Model Evaluation\n",
    "\n",
    "In this final phase of the project, we evaluate the performance of the fine-tuned model against the base model using the prepared test set. The evaluation includes both quantitative metrics and qualitative analysis through a prediction example.\n",
    "\n",
    "## Evaluation Process\n",
    "\n",
    "1. **Model Loading**\n",
    "   - Both the **base model** (\"meta-llama/Llama-3.2-3B-Instruct\") and the **fine-tuned model** were loaded for evaluation.\n",
    "\n",
    "2. **Performance Metrics**\n",
    "   - The models were evaluated using **ROUGE scores** to measure the quality of the generated outputs compared to the ground truth. The following scores were obtained:\n",
    "\n",
    "| Metric    | Base Model | Fine-Tuned Model |\n",
    "|-----------|------------|------------------|\n",
    "| **ROUGE-1**   | 0.2895     | **0.6537**         |\n",
    "| **ROUGE-2**   | 0.1145     | **0.4022**         |\n",
    "| **ROUGE-L**   | 0.1946     | **0.5090**         |\n",
    "| **ROUGE-Lsum**| 0.2620     | **0.5719**         |\n",
    "\n",
    "All the ROUGE scores have significantly improved after fine-tuning, indicating that the fine-tuned model has learned to generate more accurate and relevant outputs for the CTI analysis task.\n",
    "\n",
    "\n",
    "## Example of Prediction\n",
    "\n",
    "### **Input Prompt**\n",
    "```\n",
    "You are a skilled AI Agent capable of doing CTI Analysis.\n",
    "\n",
    "Given this threat report: Three of the backdoors, NFlog, PoisonIvy, and NewCT have previously been publicly associated with DragonOK.\n",
    "\n",
    "You will extract the main entities and their relations; finally, you will generate a diagnosis of the threat.\n",
    "```\n",
    "\n",
    "### **Ground Truth**\n",
    "```\n",
    "Entities: NFlog (malware), PoisonIvy (malware), NewCT (malware), DragonOK (threat-actor)\n",
    "Relations: NFlog to DragonOK (authored-by), PoisonIvy to DragonOK (authored-by), NewCT to DragonOK (authored-by)\n",
    "Diagnosis: Possible diagnosis: The entity DragonOK has been associated with the creation of three malware backdoors, NFlog, PoisonIvy, and NewCT, as they were previously publicly linked to this threat actor. This suggests that DragonOK may be involved in...\n",
    "```\n",
    "\n",
    "### **Fine-Tuned Model Prediction**\n",
    "```\n",
    "Entities: DragonOK (threat-actor), NFlog (malware), PoisonIvy (malware), NewCT (malware)\n",
    "Relations: DragonOK to NFlog (uses), DragonOK to PoisonIvy (uses), DragonOK to NewCT (uses)\n",
    "Diagnosis: The threat actor DragonOK has previously been associated with the use of three malware backdoors: NFlog, PoisonIvy, and NewCT. This indicates a potential cybersecurity breach and highlights the importance of monitoring and securing networks against such threats.\n",
    "```\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "- The fine-tuned model demonstrates a strong ability to extract relevant entities, establish accurate relationships, and generate a comprehensive diagnosis.  \n",
    "- Although the relations differ slightly from the ground truth (using \"uses\" instead of \"authored-by\"), the overall context and threat assessment remain valid and coherent.  \n",
    "- This example, along with the improved ROUGE scores, confirms that the fine-tuned model has effectively learned the CTI analysis task, significantly outperforming the base model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8037,
     "status": "ok",
     "timestamp": 1741971817520,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "CCo1ZsvEPsYh"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1741971817535,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "cIBncdt5P2HQ",
    "outputId": "7fdefd94-818e-430c-c6de-f60a2ec2d5a1"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4-x8NejPqpj"
   },
   "source": [
    "### Load the original model and the fine-tuned model (with LoRA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "50568bb1ae3b4c479b37749ce65fb89b",
      "45013bb1d7634130bc5c5520a58b1c56",
      "8adcf6813dba4a748931aa0488bc0e85",
      "2f008f835c8f4caf93dac1d649a701b9",
      "d7fa301f556f4822b45ceaa472a1ef79",
      "a3d773b8d18441c6894e9b59ea4abdaf",
      "1b8172b1a4604aab93513160e65a2d79",
      "a26d68e18bdb4211b91a03b7fe9d1eb3",
      "a69be176da5446c5ad2bcde278527079",
      "3b21f04e65824263a42912922c48d7ff",
      "6140ccc00d514aa8bbbbc366b04377b7"
     ]
    },
    "executionInfo": {
     "elapsed": 6984,
     "status": "ok",
     "timestamp": 1741971824549,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "utmmOGtqP-kY",
    "outputId": "410d4d56-5d66-4d73-ce8e-c5cd2a49bea2"
   },
   "outputs": [],
   "source": [
    "model_path=\"/content/drive/My Drive/Git_Portfolio/CTI/peft_model_CTI\"\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "access_token = \"YOUR HUGGING FACE ACCESS TOKEN\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=access_token)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=access_token)\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(base_model, model_path, is_trainable=False)\n",
    "peft_model = peft_model.to(device)\n",
    "peft_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500,
     "referenced_widgets": [
      "9ee68936bc96486a870599dcc1bc104a",
      "a637ee625df845418628bb799b2bebb0",
      "941d11490fb64129bb70a19104be02ca",
      "badfaed528764aeeb567e4ed9ef8c25c",
      "1ae97a8ec9fc47d787280b2be1abebec",
      "4d517e9f5dbc429b872ee703e9a1c3c9",
      "f65255b20e0b477db9516f973554d8c9",
      "2de8dee6069e4c4b88bd2afd5181dbc8",
      "eb4b4701d73a4ddaaf9f142eaf0aaf95",
      "18b82ce157cb426ca0a58db5bf3e5149",
      "e4591559753c4299a19f968e42f40c8e"
     ]
    },
    "executionInfo": {
     "elapsed": 6697,
     "status": "ok",
     "timestamp": 1741971831247,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "FR7yIxBYXSgh",
    "outputId": "a8bd14cd-f28d-4d7f-cb56-cb461ceab1aa"
   },
   "outputs": [],
   "source": [
    "# reload the base model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=access_token)\n",
    "base_model = base_model.to(device)\n",
    "base_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aelzL-ZpR1oZ"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8Xuru2IR39e"
   },
   "source": [
    "### Run the originl model and the fine-tuned model on the test set and save the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 95,
     "status": "ok",
     "timestamp": 1741971833694,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "Ybc1a86GP-h6"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the dataset\n",
    "with open('/content/drive/My Drive/Git_Portfolio/CTI/data/dataset_CTI_llama3_2-3B.pkl', 'rb') as file:\n",
    "    dataset = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 837241,
     "status": "ok",
     "timestamp": 1741973546564,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "PoYXwMDEX57r",
    "outputId": "fc35b769-4cad-433d-8ded-ababf6f34311"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "model_predictions = pd.DataFrame([],columns=['ground_truth', 'base_model', 'fine_tuned_model'])\n",
    "\n",
    "# iterate ove the test set\n",
    "for i in tqdm(range(len(dataset['test']))):\n",
    "  input_ids = dataset['test']['input_ids'][i]\n",
    "  labels = dataset['test']['labels'][i]\n",
    "\n",
    "  # remove the -100 tokens (padding), which would generate an error when using the decode() method\n",
    "  labels = [token for token in labels if token != -100]\n",
    "\n",
    "  # save the ground truth summary\n",
    "  model_predictions.loc[i,'ground_truth'] = tokenizer.decode(labels, skip_special_tokens=True)\n",
    "\n",
    "  # use the base model to predict\n",
    "  outputs_base_model = base_model.generate(\n",
    "        input_ids = torch.tensor(input_ids).unsqueeze(0).to(device),\n",
    "        eos_token_id = tokenizer.eos_token_id,\n",
    "        max_new_tokens=400\n",
    "  )\n",
    "\n",
    "  # the model used is a decoder-only model, so we need to remove the input_ids from the output\n",
    "  outputs_base_model = outputs_base_model[0][len(input_ids):]\n",
    "\n",
    "  # decode the output and put it in the dataframe\n",
    "  model_predictions.loc[i,'base_model'] = tokenizer.decode(outputs_base_model, skip_special_tokens=True)\n",
    "\n",
    "  # use the fine tuned model to predict the summary\n",
    "  outputs_peft_model = peft_model.generate(\n",
    "        input_ids = torch.tensor(input_ids).unsqueeze(0).to(device),\n",
    "        eos_token_id = tokenizer.eos_token_id,\n",
    "        max_new_tokens=400\n",
    "  )\n",
    "\n",
    "  # the model used is a decoder-only model, so we need to remove the input_ids from the output\n",
    "  outputs_peft_model = outputs_peft_model[0][len(input_ids):]\n",
    "\n",
    "  # decode the output and put it in the dataframe\n",
    "  model_predictions.loc[i,'fine_tuned_model'] = tokenizer.decode(outputs_peft_model, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1741973555887,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "byKx0Kv02xWX"
   },
   "outputs": [],
   "source": [
    "# save the predictions on the Test Set\n",
    "model_predictions.to_csv('/content/drive/My Drive/Git_Portfolio/CTI/data/model_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EpKSY0IvRT28"
   },
   "source": [
    "### Compute the metric ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1741973565155,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "dVae0RI5CGcD"
   },
   "outputs": [],
   "source": [
    "# load the predictions of the test set\n",
    "model_predictions = pd.read_csv('/content/drive/My Drive/Git_Portfolio/CTI/data/model_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1741973598769,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "M4QmOvhbB82s"
   },
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1741973599670,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "rFNKjXwrRXu9"
   },
   "outputs": [],
   "source": [
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1457,
     "status": "ok",
     "timestamp": 1741973604814,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "T_0rnmPBP-fW"
   },
   "outputs": [],
   "source": [
    "# compute the score for the base model and for the fine tuned model\n",
    "\n",
    "base_model_results = rouge.compute(\n",
    "    predictions=model_predictions['base_model'].to_list(),\n",
    "    references=model_predictions['ground_truth'].to_list(),\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "peft_model_results = rouge.compute(\n",
    "    predictions=model_predictions['fine_tuned_model'].to_list(),\n",
    "    references=model_predictions['ground_truth'].to_list(),\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1741973606773,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "Fong2eiCEd8K",
    "outputId": "4a494593-0847-47ac-e1fd-16f1cb32022e"
   },
   "outputs": [],
   "source": [
    "print('Base Model scores:')\n",
    "for score in base_model_results:\n",
    "  print(f'{score}: {base_model_results[score]}')\n",
    "\n",
    "print('\\n --------------- \\n')\n",
    "\n",
    "print('Fine-tuned Model scores:')\n",
    "for score in peft_model_results:\n",
    "  print(f'{score}: {peft_model_results[score]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MkAo2SbPFaZO"
   },
   "source": [
    "#### **We can notic how all the rouge scores improved with fine-tuning!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tg6yIMF1Psk3"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1741973723388,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "j0m5ntRtPzP-"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# select three random dialogues from the list\n",
    "indeces = random.sample(range(len(model_predictions)), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7EiSrUu3cXT"
   },
   "source": [
    "### Human evaluation of the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ir_CblCFJVMk"
   },
   "source": [
    "#### **We can notice that the output of the fine-tuned model is extensive and very close to the original summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1741973724951,
     "user": {
      "displayName": "Andrea Crobu",
      "userId": "01110819918100512364"
     },
     "user_tz": -60
    },
    "id": "UpaJb8n9PzNH",
    "outputId": "56e88f9e-1b4f-4cc6-97c3-1af539340cb0"
   },
   "outputs": [],
   "source": [
    "\n",
    "# print the original dialogue and compare the grounf truth to the base model prediction and the fine-tuned model\n",
    "for idx in indeces:\n",
    "  print()\n",
    "  print('-'*150)\n",
    "  print('-'*150)\n",
    "  print()\n",
    "  print(f'Report {idx}')\n",
    "  print()\n",
    "\n",
    "  report = tokenizer.decode(dataset['test']['input_ids'][idx], skip_special_tokens=True)\n",
    "  print(report)\n",
    "\n",
    "  print()\n",
    "  print('-'*150)\n",
    "  print()\n",
    "\n",
    "  print('Ground truth:\\n')\n",
    "  print(model_predictions['ground_truth'][idx])\n",
    "\n",
    "  print()\n",
    "  print('-'*150)\n",
    "  print()\n",
    "\n",
    "  print('Fine-tuned model:\\n')\n",
    "  print(model_predictions['fine_tuned_model'][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RaeeHvRIt_wf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
